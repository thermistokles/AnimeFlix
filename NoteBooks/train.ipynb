{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad18525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 158.8330535888672\n",
      "Epoch 2/20 - Loss: 122.42342376708984\n",
      "Epoch 3/20 - Loss: 109.28271484375\n",
      "Epoch 4/20 - Loss: 94.76754760742188\n",
      "Epoch 5/20 - Loss: 81.03024291992188\n",
      "Epoch 6/20 - Loss: 64.81282043457031\n",
      "Epoch 7/20 - Loss: 58.09478759765625\n",
      "Epoch 8/20 - Loss: 50.39680480957031\n",
      "Epoch 9/20 - Loss: 44.56081771850586\n",
      "Epoch 10/20 - Loss: 30.89578628540039\n",
      "Epoch 11/20 - Loss: 27.647438049316406\n",
      "Epoch 12/20 - Loss: 20.94245719909668\n",
      "Epoch 13/20 - Loss: 15.411995887756348\n",
      "Epoch 14/20 - Loss: 11.883370399475098\n",
      "Epoch 15/20 - Loss: 9.148985862731934\n",
      "Epoch 16/20 - Loss: 5.834691047668457\n",
      "Epoch 17/20 - Loss: 5.22075891494751\n",
      "Epoch 18/20 - Loss: 3.715306282043457\n",
      "Epoch 19/20 - Loss: 3.1637372970581055\n",
      "Epoch 20/20 - Loss: 2.312487840652466\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load and process data\n",
    "df_anime = pd.read_csv('C:/Users/vigne/OneDrive/Documents/WPI/Sem_2/IR/project/archive/animes.csv')\n",
    "df_rating = pd.read_csv('C:/Users/vigne/OneDrive/Documents/WPI/Sem_2/IR/project/archive/rating.csv')\n",
    "df_anime = df_anime[['uid', 'title']]\n",
    "df_anime.rename(columns={'uid': 'anime_id'}, inplace=True)\n",
    "df_anime = df_anime.drop_duplicates()\n",
    "\n",
    "df_rating_cp = df_rating[df_rating['rating'] != -1]\n",
    "df_rating_cp = df_rating_cp.sample(frac=1)[:1000000].sort_values('user_id')\n",
    "\n",
    "# Map user and anime ids to integer indices\n",
    "user_mapping = {user_id: idx for idx, user_id in enumerate(df_rating_cp.user_id.unique())}\n",
    "anime_mapping = {anime_id: idx for idx, anime_id in enumerate(df_rating_cp.anime_id.unique())}\n",
    "\n",
    "df_rating_cp['user_id'] = df_rating_cp['user_id'].apply(lambda x: user_mapping[x])\n",
    "df_rating_cp['anime_id'] = df_rating_cp['anime_id'].apply(lambda x: anime_mapping[x])\n",
    "\n",
    "# Define neural network-based matrix factorization model\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_anime, n_factors):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.anime_factors = nn.Embedding(n_anime, n_factors)\n",
    "\n",
    "    def forward(self, user, anime):\n",
    "        return (self.user_factors(user) * self.anime_factors(anime)).sum(1)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "n_users = len(user_mapping)\n",
    "n_anime = len(anime_mapping)\n",
    "n_factors = 100\n",
    "\n",
    "model = MatrixFactorization(n_users, n_anime, n_factors)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "batch_size = 1024\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    shuffled_indices = torch.randperm(len(df_rating_cp))\n",
    "    for batch_start in range(0, len(df_rating_cp), batch_size):\n",
    "        batch_indices = shuffled_indices[batch_start:batch_start + batch_size]\n",
    "        user_batch = torch.tensor(df_rating_cp.iloc[batch_indices]['user_id'].values, dtype=torch.long)\n",
    "        anime_batch = torch.tensor(df_rating_cp.iloc[batch_indices]['anime_id'].values, dtype=torch.long)\n",
    "        rating_batch = torch.tensor(df_rating_cp.iloc[batch_indices]['rating'].values, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_batch, anime_batch)\n",
    "        loss = loss_func(predictions, rating_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316e73c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommended Anime:\n",
      "   anime_id                                              title\n",
      "0      5460         Detective Conan Movie 13: The Raven Chaser\n",
      "1      3536                                            Youshou\n",
      "2     16648                    Youchien Senshi: Hanamaru Girls\n",
      "3     10604     Hidan no Aria: Butei ga Kitarite Onsen Kenshuu\n",
      "4     15893                                             Crash!\n",
      "5      2814                               Dondon Domeru to Ron\n",
      "6      4934                                                A.F\n",
      "7     21575  Koukaku Kidoutai Arise: Ghost in the Shell - L...\n",
      "8      7568                   Umineko no Naku Koro ni Specials\n",
      "9     18449  Mobile Suit Gundam Battlefield Record: Avant-T...\n"
     ]
    }
   ],
   "source": [
    "user_id = 43\n",
    "user_index = user_mapping[user_id]\n",
    "\n",
    "not_watched = [anime_idx for anime_idx in range(n_anime) if anime_idx not in df_rating_cp[df_rating_cp['user_id'] == user_index]['anime_id'].values]\n",
    "\n",
    "# Get scores for not watched anime\n",
    "user_tensor = torch.tensor([user_index] * len(not_watched), dtype=torch.long)\n",
    "anime_tensor = torch.tensor(not_watched, dtype=torch.long)\n",
    "anime_scores = model(user_tensor, anime_tensor)\n",
    "\n",
    "# Get top 10 anime indices\n",
    "top_10_indices = torch.topk(anime_scores, 10).indices\n",
    "\n",
    "# Get top 10 anime ids\n",
    "top_10_anime_ids = [list(anime_mapping.keys())[list(anime_mapping.values()).index(idx)] for idx in top_10_indices.tolist()]\n",
    "\n",
    "# Get top 10 anime titles\n",
    "recommended_anime = df_anime[df_anime['anime_id'].isin(top_10_anime_ids)].reset_index(drop=True)\n",
    "\n",
    "print(\"Top 10 Recommended Anime:\")\n",
    "print(recommended_anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bd793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommended Anime:\n",
      "   anime_id                                              title\n",
      "0      9735                   Gintama: Shinyaku Benizakura-hen\n",
      "1      7266                                     Binkan Athlete\n",
      "2      5402                                     Maid Meshimase\n",
      "3      5612                                        Terra Story\n",
      "4     17635                          Koitabi: True Tours Nanto\n",
      "5     25259  Persona 4 the Animation: A Brief Lesson on Iza...\n",
      "6     14093                      Pokemon Best Wishes! Season 2\n",
      "7      2408  Keroro Gunsou Movie 2: Shinkai no Princess de ...\n",
      "8      4312                            Hokuto no Ken: Toki-den\n",
      "9      9014                                      Kuttsukiboshi\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have a new user with ID 100, and we want to recommend 10 animes to them\n",
    "\n",
    "# Step 1: Map the new user ID to an integer index\n",
    "new_user_index = user_mapping[100]\n",
    "\n",
    "# Step 2: Create a list of not-yet-watched anime for the new user\n",
    "not_watched = [anime_idx for anime_idx in range(n_anime) if anime_idx not in df_rating_cp[df_rating_cp['user_id'] == new_user_index]['anime_id'].values]\n",
    "\n",
    "# Step 3: Get scores for not-yet-watched anime\n",
    "user_tensor = torch.tensor([new_user_index] * len(not_watched), dtype=torch.long)\n",
    "anime_tensor = torch.tensor(not_watched, dtype=torch.long)\n",
    "anime_scores = model(user_tensor, anime_tensor)\n",
    "\n",
    "# Step 4: Get top K anime indices\n",
    "top_k_indices = torch.topk(anime_scores, 10).indices\n",
    "\n",
    "# Step 5: Map the top K anime indices back to their respective anime IDs and titles\n",
    "top_k_anime_ids = [list(anime_mapping.keys())[list(anime_mapping.values()).index(idx)] for idx in top_k_indices.tolist()]\n",
    "recommended_anime = df_anime[df_anime['anime_id'].isin(top_k_anime_ids)].reset_index(drop=True)\n",
    "\n",
    "# Print the top 10 recommended anime titles\n",
    "print(\"Top 10 Recommended Anime:\")\n",
    "print(recommended_anime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad73674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file called 'model.pth'\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617dc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'user_mapping': user_mapping, 'anime_mapping': anime_mapping}\n",
    "torch.save(mapping_dict, 'mapping.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c452fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
